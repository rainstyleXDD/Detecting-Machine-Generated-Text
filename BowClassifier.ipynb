{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ec19261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "783c6136",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f139e78",
   "metadata": {},
   "source": [
    "# Exploritory Data analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bfb7233",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_json(path_or_buf=\"./data/domain1_train.json/domain1_train.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ec4994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     [70, 746, 825, 109, 2083, 0, 2, 0, 0, 0, 9, 0,...\n",
       "label                                                    1\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcb17f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[70, 746, 825, 109, 2083, 0, 2, 0, 0, 0, 9, 0, 1004, 19, 0, 0, 7, 913]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49a9f30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1['label'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "392de681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[70, 746, 825, 109, 2083, 0, 2, 0, 0, 0, 9, 0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1209, 179, 1952, 4, 4959, 7, 0, 2, 978, 1522,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[287, 3, 3330, 0, 23, 12, 13, 465, 74, 8, 0, 8...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 3, 592, 19, 2, 706, 1439, 2575, 7, 2, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[9, 2, 110, 12, 42, 32, 44, 361, 9, 3860, 2358...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  [70, 746, 825, 109, 2083, 0, 2, 0, 0, 0, 9, 0,...      1\n",
       "1  [1209, 179, 1952, 4, 4959, 7, 0, 2, 978, 1522,...      1\n",
       "2  [287, 3, 3330, 0, 23, 12, 13, 465, 74, 8, 0, 8...      1\n",
       "3  [0, 0, 3, 592, 19, 2, 706, 1439, 2575, 7, 2, 0...      1\n",
       "4  [9, 2, 110, 12, 42, 32, 44, 361, 9, 3860, 2358...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d984313",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_all_d1 = d1[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56abf900",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_all_d1 = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75571eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in texts_all_d1:\n",
    "    for word in text:\n",
    "        counter_all_d1[word] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d8f9adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4926"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counter_all_d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c1febe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4836"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_human_d1 = d1[d1[\"label\"] == 1][\"text\"]\n",
    "counter_human_d1 = Counter()\n",
    "for text in texts_human_d1:\n",
    "    for word in text:\n",
    "        counter_human_d1[word] +=1\n",
    "len(counter_human_d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c26815b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1[\"text\"].apply(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6a541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_human_d1.apply(len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f399adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_ai_d1 = d1[d1[\"label\"] == 0][\"text\"]\n",
    "counter_ai_d1 = Counter()\n",
    "for text in texts_ai_d1:\n",
    "    for word in text:\n",
    "        counter_ai_d1[word] +=1\n",
    "len(counter_ai_d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd604db",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_ai_d1.apply(len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15e087fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = pd.read_json(path_or_buf=\"./data/domain2_train.json/domain2_train.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d337cced",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_all_d2 = d2[\"text\"]\n",
    "counter_all_d2 = Counter()\n",
    "for text in texts_all_d2:\n",
    "    for word in text:\n",
    "        counter_all_d2[word] +=1\n",
    "len(counter_all_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8069c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_human_d2 = d2[d2[\"label\"] == 1][\"text\"]\n",
    "counter_human_d2 = Counter()\n",
    "for text in texts_human_d2:\n",
    "    for word in text:\n",
    "        counter_human_d2[word] +=1\n",
    "len(counter_human_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b94a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts_human_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc3fcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_human_d2.apply(len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d1faf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_human_d2.apply(len).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2fc978",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_ai_d2 = d2[d2[\"label\"] == 0][\"text\"]\n",
    "counter_ai_d2 = Counter()\n",
    "for text in texts_ai_d2:\n",
    "    for word in text:\n",
    "        counter_ai_d2[word] +=1\n",
    "len(counter_ai_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_ai_d2.apply(len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d944a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts_ai_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c8686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip(*counter_all_d1.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674798a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919cf637",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_all_d1.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbdd322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a866f23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "testList2_human = [log(elem2) for elem1, elem2 in counter_human_d1.most_common()]\n",
    "testList2_ai = [log(elem2) for elem1, elem2 in counter_ai_d1.most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793ba61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "testList2_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457a3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(testList2_human)\n",
    "\n",
    "plt.plot(testList2_ai)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29737d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "testList_human = [log(elem2*6) for elem1, elem2 in counter_human_d2.most_common()]\n",
    "testList_ai = [log(elem2) for elem1, elem2 in counter_ai_d2.most_common()]\n",
    "plt.plot(testList_human)\n",
    "\n",
    "plt.plot(testList_ai)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f2afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts_ai_d2)/len(texts_human_d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f082b214",
   "metadata": {},
   "source": [
    "# Feature Engineering/Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "218f1333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, f1_score\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51afa852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BOW(row):\n",
    "    text = row['text']\n",
    "    bow = [0 for i in range(VOCAB_SIZE)]\n",
    "    for idx in text:\n",
    "        bow[idx]+=1\n",
    "    return np.array(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37d33d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vocabulary explicitly as a list of integers from 0 to 4999\n",
    "vocabulary = [str(i) for i in range(VOCAB_SIZE)]\n",
    "\n",
    "# Initialize the CountVectorizer with the predefined vocabulary\n",
    "vectorizer = CountVectorizer(vocabulary=vocabulary)\n",
    "\n",
    "# Fit and transform the text data to obtain a feature matrix\n",
    "bow_matrix_1 = vectorizer.fit_transform(d1[\"text\"].apply(lambda x: \" \".join(map(str, x))))\n",
    "\n",
    "# Convert the feature matrix to a dense NumPy array if needed\n",
    "#dense_bow_matrix = bow_matrix.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d27eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bow_matrix_1, d1['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a4558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5269ed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a95c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_matrix_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b492e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vt = VarianceThreshold(threshold=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afd25c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train a logistic regression model.\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set.\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040e1cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(model, bow_matrix_1, d1['label'], cv=5,scoring=('balanced_accuracy', 'f1', 'roc_auc'))\n",
    "print(scores['test_balanced_accuracy'].mean())\n",
    "print(scores['test_f1'].mean())\n",
    "print(scores['test_roc_auc'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b48389",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vt_1 = vt.fit_transform(bow_matrix_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031375a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vt_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3feb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bow_vt_1, d1['label'], test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set.\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5ddb5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81225f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix_1 = tfidf.fit_transform(bow_matrix_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaebbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t_train, X_t_test, y_t_train, y_t_test = train_test_split(tfidf_matrix_1, d1['label'], test_size=0.2, random_state=42)\n",
    "model.fit(X_t_train, y_t_train)\n",
    "\n",
    "# Predict on the test set.\n",
    "y_t_pred = model.predict(X_t_test)\n",
    "\n",
    "# Evaluate the model.\n",
    "accuracy = accuracy_score(y_t_test, y_t_pred)\n",
    "report = classification_report(y_t_test, y_t_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9becd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(model, tfidf_matrix_1, d1['label'], cv=5,scoring=('balanced_accuracy', 'f1', 'roc_auc'))\n",
    "print(scores['test_balanced_accuracy'].mean())\n",
    "print(scores['test_f1'].mean())\n",
    "print(scores['test_roc_auc'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f92461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vt1 = VarianceThreshold(threshold=0.0001)\n",
    "tfidf_vt_1 = vt1.fit_transform(tfidf_matrix_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c901c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vt_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dd47b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_vt_1, d1['label'], test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set.\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe95daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_matrix_2 = vectorizer.fit_transform(d2[\"text\"].apply(lambda x: \" \".join(map(str, x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ba784",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bow_matrix_2, d2['label'], test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set.\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"f1: {f1}\")\n",
    "print(f\"roc_auc_score: {roc_auc}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371612ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f583ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acee041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = cross_validate(model, bow_matrix_2, d2['label'], cv=5,scoring=('balanced_accuracy', 'f1', 'roc_auc'))\n",
    "# print(scores['test_balanced_accuracy'].mean())\n",
    "# print(scores['test_f1'].mean())\n",
    "# print(scores['test_roc_auc'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b0e34ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "smote = SMOTE()\n",
    "bsmote = BorderlineSMOTE()\n",
    "svmsmote = SVMSMOTE()\n",
    "adasyn = ADASYN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611f3f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_oversample(X_train, y_train, X_test, y_test, oversample, model):\n",
    "    X_train_o, y_train_o = oversample.fit_resample(X_train, y_train)\n",
    "    model.fit(X_train_o, y_train_o)\n",
    "\n",
    "    # Predict on the test set.\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model.\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"f1: {f1}\")\n",
    "    print(f\"roc_auc_score: {roc_auc}\")\n",
    "    print(report)\n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55148bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_oversample(X_train, y_train, X_test, y_test, oversample, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90bd41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_o, y_train_o = oversample.fit_resample(X_train, y_train)\n",
    "model.fit(X_train_o, y_train_o)\n",
    "\n",
    "# Predict on the test set.\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22b5949",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_oversample(X_train, y_train, X_test, y_test, smote, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb12ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_oversample(X_train, y_train, X_test, y_test, bsmote, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b1246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_oversample(X_train, y_train, X_test, y_test, svmsmote, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d0cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_oversample(X_train, y_train, X_test, y_test, adasyn, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05db853",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix_2 = tfidf.fit_transform(bow_matrix_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af7c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix_2, d2['label'], test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set.\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"f1: {f1}\")\n",
    "print(f\"roc_auc_score: {roc_auc}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f847f500",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1957520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(model, tfidf_matrix_2, d2['label'], cv=5,scoring=('balanced_accuracy', 'f1', 'roc_auc'))\n",
    "print(scores['test_balanced_accuracy'].mean())\n",
    "print(scores['test_f1'].mean())\n",
    "print(scores['test_roc_auc'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff903887",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_oversample(X_train, y_train, X_test, y_test, smote, model)\n",
    "test_oversample(X_train, y_train, X_test, y_test, bsmote, model)\n",
    "test_oversample(X_train, y_train, X_test, y_test, svmsmote, model)\n",
    "test_oversample(X_train, y_train, X_test, y_test, adasyn, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2592309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vt_2 = vt1.fit_transform(tfidf_matrix_2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_vt_2, d2['label'], test_size=0.2, random_state=42)\n",
    "tfidf_vt_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591a6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_oversample(X_train, y_train, X_test, y_test, smote, model)\n",
    "test_oversample(X_train, y_train, X_test, y_test, bsmote, model)\n",
    "test_oversample(X_train, y_train, X_test, y_test, svmsmote, model)\n",
    "test_oversample(X_train, y_train, X_test, y_test, adasyn, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0668b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.Series(X.ravel()).apply(lambda x: \" \".join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4c6fc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_val(d1x, d1y, d2x, d2y, k):\n",
    "    output = []\n",
    "    \n",
    "    samples_per_class_in_test = 250  # Adjust as needed\n",
    "\n",
    "    # Initialize empty lists to store the train and test indices\n",
    "    train_indices1 = [[] for i in range(k)]\n",
    "    train_indices2 = [[] for i in range(k)]\n",
    "    test_indices1 = [[] for i in range(k)]\n",
    "    test_indices2 = [[] for i in range(k)]\n",
    "    \n",
    "    for class_label in [0,1]:\n",
    "        # Get the indices of samples belonging to the current class\n",
    "        class_indices1 = np.where(d1y == class_label)[0]\n",
    "        class_indices2 = np.where(d2y == class_label)[0]\n",
    "\n",
    "        # Randomly select samples_per_class_in_test samples from this class\n",
    "        selected_indices1 = np.random.choice(class_indices1, samples_per_class_in_test*k, replace=False)\n",
    "        selected_indices2 = np.random.choice(class_indices2, samples_per_class_in_test*k, replace=False)\n",
    "        \n",
    "        selected_indices1 = selected_indices1.reshape(k, samples_per_class_in_test)\n",
    "        selected_indices2 = selected_indices2.reshape(k, samples_per_class_in_test)\n",
    "        \n",
    "        for i in range(k):\n",
    "            test_indices1[i].extend(selected_indices1[i])\n",
    "            test_indices2[i].extend(selected_indices2[i])\n",
    "            \n",
    "\n",
    "            # Add the remaining samples to the train set indices\n",
    "            remaining_indices = np.setdiff1d(class_indices1, selected_indices1[i])\n",
    "            train_indices1[i].extend(remaining_indices)\n",
    "            \n",
    "            remaining_indices = np.setdiff1d(class_indices2, selected_indices2[i])\n",
    "            train_indices2[i].extend(remaining_indices)\n",
    "    print(len(train_indices1[0]))\n",
    "    print(len(train_indices2[0]))\n",
    "    print(type(d1x[train_indices1[0]]))\n",
    "    print(type(d1y[train_indices1[0]]))\n",
    "    for i in range(k):\n",
    "        # Split the data into train and test sets using the selected indices\n",
    "        output.append([d1x[train_indices1[i]].append(d2x[train_indices2[i]], ignore_index = True), d1x[test_indices1[i]].append(d2x[test_indices2[i]], ignore_index= True), d1y[train_indices1[i]].append(d2y[train_indices2[i]], ignore_index= True), d1y[test_indices1[i]].append(d2y[test_indices2[i]], ignore_index= True)])\n",
    "    \n",
    "    return output, len(train_indices1[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14a5619a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19000\n",
      "14400\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "data, d1_len = get_k_val(d1['text'], d1['label'], d2['text'], d2['label'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60a9bb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8c8c504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_data = get_k_val(bow_matrix_1.toarray, d1['label'], bow_matrix_2, d2['label'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3059278",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add23b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baf75aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[19000:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a926ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = X_train[19000:]\n",
    "y_train_2 = y_train[19000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5ee679",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c89cca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc585234",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e50f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708c80df",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e366085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_matrix_train = vectorizer.fit_transform(X_train.apply(lambda x: \" \".join(map(str, x))))\n",
    "bow_matrix_test = vectorizer.transform(X_test.apply(lambda x: \" \".join(map(str, x))))\n",
    "\n",
    "tfidf_matrix_train = tfidf.fit_transform(bow_matrix_train)\n",
    "tfidf_matrix_test = tfidf.transform(bow_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057799d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_matrix_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a719b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_matrix_train[:19000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a632526",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:19000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f20db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_matrix_train_2 = bow_matrix_train[19000:]\n",
    "y_train_2 = y_train[19000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78b9890",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_matrix_train_2_o, y_train_2_o = oversample.fit_resample(bow_matrix_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a06616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_matrix_train_2_o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d141f065",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_2_o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1076aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d966348c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bow_matrix_train_2_o' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_train_o \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mvstack((bow_matrix_train[:\u001b[38;5;241m19000\u001b[39m], \u001b[43mbow_matrix_train_2_o\u001b[49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bow_matrix_train_2_o' is not defined"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "X_train_o = sp.sparse.vstack((bow_matrix_train[:19000], bow_matrix_train_2_o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9fa95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(bow_matrix_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076fbcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d7d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_o = np.append(y_train[:19000], y_train_2_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88d9201",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a224b8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_o, y_train_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7923e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set.\n",
    "y_pred = model.predict(bow_matrix_test)\n",
    "\n",
    "# Evaluate the model.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, model.predict_proba(bow_matrix_test)[:, 1])\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"f1: {f1}\")\n",
    "print(f\"roc_auc_score: {roc_auc}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37ce73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bow_matrix_train.shape)\n",
    "print(bow_matrix_test.shape)\n",
    "print(tfidf_matrix_train.shape)\n",
    "print(tfidf_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825c3894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X_train, y_train, X_test, y_test, model, d1_len, oversample = None):\n",
    "    if oversample is not None:\n",
    "        \n",
    "        X_train_2_o, y_train_2_o = oversample.fit_resample(X_train[d1_len:], y_train[d1_len:])\n",
    "        X_train_o = sp.sparse.vstack((X_train[:d1_len], X_train_2_o))\n",
    "        y_train_o = np.append(y_train[:d1_len], y_train_2_o)\n",
    "        \n",
    "        model.fit(X_train_o, y_train_o)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set.\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model.\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"f1: {f1}\")\n",
    "    print(f\"roc_auc_score: {roc_auc}\")\n",
    "    print(report)\n",
    "    print(\"-\"*50)\n",
    "    # Predict on the test set.\n",
    "    print('Domain1')\n",
    "    y_pred = model.predict(X_test[:500])\n",
    "    # Evaluate the model.\n",
    "    accuracy = accuracy_score(y_test[:500], y_pred)\n",
    "    f1 = f1_score(y_test[:500], y_pred)\n",
    "    roc_auc = roc_auc_score(y_test[:500], model.predict_proba(X_test[:500])[:, 1])\n",
    "    report = classification_report(y_test[:500], y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"f1: {f1}\")\n",
    "    print(f\"roc_auc_score: {roc_auc}\")\n",
    "    print(report)\n",
    "    # Predict on the test set.\n",
    "    print(\"-\"*50)\n",
    "    print(\"Domain 2\")\n",
    "    \n",
    "    y_pred = model.predict(X_test[500:])\n",
    "    # Evaluate the model.\n",
    "    accuracy = accuracy_score(y_test[500:], y_pred)\n",
    "    f1 = f1_score(y_test[500:], y_pred)\n",
    "    roc_auc = roc_auc_score(y_test[500:], model.predict_proba(X_test[500:])[:, 1])\n",
    "    report = classification_report(y_test[500:], y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"f1: {f1}\")\n",
    "    print(f\"roc_auc_score: {roc_auc}\")\n",
    "    print(report)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b524e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(bow_matrix_train, y_train, bow_matrix_test, y_test, model, d1_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264340f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"oversample\")\n",
    "evaluate(bow_matrix_train, y_train, bow_matrix_test, y_test, model, d1_len, oversample)\n",
    "print(\"smote\")\n",
    "evaluate(bow_matrix_train, y_train, bow_matrix_test, y_test, model, d1_len, smote)\n",
    "print(\"bsmote\")\n",
    "evaluate(bow_matrix_train, y_train, bow_matrix_test, y_test, model, d1_len, bsmote)\n",
    "print(\"svmsmote\")\n",
    "evaluate(bow_matrix_train, y_train, bow_matrix_test, y_test, model, d1_len, svmsmote)\n",
    "print(\"adasyn\")\n",
    "evaluate(bow_matrix_train, y_train, bow_matrix_test, y_test, model, d1_len, adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58df8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(tfidf_matrix_train, y_train, tfidf_matrix_test, y_test, model, d1_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4afe1ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"oversample\")\n",
    "evaluate(tfidf_matrix_train, y_train, tfidf_matrix_test, y_test, model, d1_len, oversample)\n",
    "print(\"smote\")\n",
    "evaluate(tfidf_matrix_train, y_train, tfidf_matrix_test, y_test, model, d1_len, smote)\n",
    "print(\"bsmote\")\n",
    "evaluate(tfidf_matrix_train, y_train, tfidf_matrix_test, y_test, model, d1_len, bsmote)\n",
    "print(\"svmsmote\")\n",
    "evaluate(tfidf_matrix_train, y_train, tfidf_matrix_test, y_test, model, d1_len, svmsmote)\n",
    "print(\"adasyn\")\n",
    "evaluate(tfidf_matrix_train, y_train, tfidf_matrix_test, y_test, model, d1_len, adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591549f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02d60d4c",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8c0621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(d2['label']), y=d2['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe7744",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622dc85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix_2, d2['label'], test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set.\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"f1: {f1}\")\n",
    "print(f\"roc_auc_score: {roc_auc}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cfd752",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_oversample(X_train, y_train, X_test, y_test, smote, model)\n",
    "test_oversample(X_train, y_train, X_test, y_test, bsmote, model)\n",
    "test_oversample(X_train, y_train, X_test, y_test, svmsmote, model)\n",
    "test_oversample(X_train, y_train, X_test, y_test, adasyn, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c734da8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_vt_2, d2['label'], test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set.\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"f1: {f1}\")\n",
    "print(f\"roc_auc_score: {roc_auc}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3725ad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_oversample(X_train, y_train, X_test, y_test, smote, model)\n",
    "test_oversample(X_train, y_train, X_test, y_test, bsmote, model)\n",
    "test_oversample(X_train, y_train, X_test, y_test, svmsmote, model)\n",
    "test_oversample(X_train, y_train, X_test, y_test, adasyn, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca70ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b2fa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(bow_matrix_train, y_train, bow_matrix_test, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1fb1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(tfidf_matrix_train, y_train, tfidf_matrix_test, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c136d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "param={'solver': ['lbfgs', 'sag','newton-cholesky'],\n",
    "       'c':[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100]}\n",
    "best_score = 0\n",
    "best_solver = ''\n",
    "best_c = 0\n",
    "for s in param['solver']:\n",
    "    for c in param['c']:\n",
    "        lr = LogisticRegression(C = c, solver = s, class_weight='balanced')\n",
    "        lr.fit(bow_matrix_train, y_train)\n",
    "        result = lr.score(bow_matrix_test, y_test)\n",
    "        print(\"Solver: \"+str(s)+\", c: \"+str(c)+\", accurancy: \" + str(result))\n",
    "        if result > best_score:\n",
    "            best_score = result\n",
    "            best_solver = s\n",
    "            best_c = c\n",
    "lr =LogisticRegression(C = best_c, solver = best_solver, class_weight='balanced')\n",
    "lr.fit(bow_matrix_train, y_train)\n",
    "print('best param: solver = ' +str(best_solver)+ \", c: \"+str(best_c)+\" with accuracy:\" + str(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ab10a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "param={'solver': ['lbfgs', 'sag','newton-cholesky'],\n",
    "       'c':[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100]}\n",
    "best_score = 0\n",
    "best_solver = ''\n",
    "best_c = 0\n",
    "for s in param['solver']:\n",
    "    for c in param['c']:\n",
    "        lr = LogisticRegression(C = c, solver = s, class_weight='balanced')\n",
    "        lr.fit(tfidf_matrix_train, y_train)\n",
    "        result = lr.score(tfidf_matrix_test, y_test)\n",
    "        print(\"Solver: \"+str(s)+\", c: \"+str(c)+\", accurancy: \" + str(result))\n",
    "        if result > best_score:\n",
    "            best_score = result\n",
    "            best_solver = s\n",
    "            best_c = c\n",
    "lr =LogisticRegression(C = best_c, solver = best_solver, class_weight='balanced')\n",
    "lr.fit(bow_matrix_train, y_train)\n",
    "print('best param: solver = ' +str(best_solver)+ \", c: \"+str(best_c)+\" with accuracy:\" + str(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1669f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e44973",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "X_train_o, y_train_o = oversample.fit_resample(bow_matrix_train, y_train)\n",
    "    \n",
    "param={'solver': ['lbfgs', 'sag','newton-cholesky'],\n",
    "       'c':[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100]}\n",
    "best_score = 0\n",
    "best_solver = ''\n",
    "best_c = 0\n",
    "for s in param['solver']:\n",
    "    for c in param['c']:\n",
    "        lr = LogisticRegression(C = c, solver = s, class_weight='balanced')\n",
    "        lr.fit(X_train_o, y_train_o)\n",
    "        result = lr.score(bow_matrix_test, y_test)\n",
    "        print(\"Solver: \"+str(s)+\", c: \"+str(c)+\", accurancy: \" + str(result))\n",
    "        if result > best_score:\n",
    "            best_score = result\n",
    "            best_solver = s\n",
    "            best_c = c\n",
    "lr =LogisticRegression(C = best_c, solver = best_solver, class_weight='balanced')\n",
    "lr.fit(bow_matrix_train, y_train)\n",
    "print('best param: solver = ' +str(best_solver)+ \", c: \"+str(c)+\" with accuracy:\" + str(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9ce2749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver: lbfgs, c: 0.001, accurancy: 0.621\n",
      "Solver: lbfgs, c: 0.005, accurancy: 0.655\n",
      "Solver: lbfgs, c: 0.01, accurancy: 0.663\n",
      "Solver: lbfgs, c: 0.05, accurancy: 0.687\n",
      "Solver: lbfgs, c: 0.1, accurancy: 0.698\n",
      "Solver: lbfgs, c: 0.5, accurancy: 0.716\n",
      "Solver: lbfgs, c: 1, accurancy: 0.718\n",
      "Solver: lbfgs, c: 5, accurancy: 0.729\n",
      "Solver: lbfgs, c: 10, accurancy: 0.732\n",
      "Solver: lbfgs, c: 50, accurancy: 0.723\n",
      "Solver: lbfgs, c: 100, accurancy: 0.721\n",
      "Solver: sag, c: 0.001, accurancy: 0.621\n",
      "Solver: sag, c: 0.005, accurancy: 0.655\n",
      "Solver: sag, c: 0.01, accurancy: 0.663\n",
      "Solver: sag, c: 0.05, accurancy: 0.687\n",
      "Solver: sag, c: 0.1, accurancy: 0.698\n",
      "Solver: sag, c: 0.5, accurancy: 0.716\n",
      "Solver: sag, c: 1, accurancy: 0.718\n",
      "Solver: sag, c: 5, accurancy: 0.728\n",
      "Solver: sag, c: 10, accurancy: 0.732\n",
      "Solver: sag, c: 50, accurancy: 0.727\n",
      "Solver: sag, c: 100, accurancy: 0.724\n",
      "Solver: newton-cholesky, c: 0.001, accurancy: 0.621\n",
      "Solver: newton-cholesky, c: 0.005, accurancy: 0.655\n",
      "Solver: newton-cholesky, c: 0.01, accurancy: 0.663\n",
      "Solver: newton-cholesky, c: 0.05, accurancy: 0.687\n",
      "Solver: newton-cholesky, c: 0.1, accurancy: 0.698\n",
      "Solver: newton-cholesky, c: 0.5, accurancy: 0.716\n",
      "Solver: newton-cholesky, c: 1, accurancy: 0.718\n",
      "Solver: newton-cholesky, c: 5, accurancy: 0.728\n",
      "Solver: newton-cholesky, c: 10, accurancy: 0.732\n",
      "Solver: newton-cholesky, c: 50, accurancy: 0.727\n",
      "Solver: newton-cholesky, c: 100, accurancy: 0.724\n",
      "best param: solver = lbfgs, c: 100 with accuracy:0.732\n"
     ]
    }
   ],
   "source": [
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "X_train_o, y_train_o = oversample.fit_resample(tfidf_matrix_train, y_train)\n",
    "    \n",
    "param={'solver': ['lbfgs', 'sag','newton-cholesky'],\n",
    "       'c':[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100]}\n",
    "best_score = 0\n",
    "best_solver = ''\n",
    "best_c = 0\n",
    "for s in param['solver']:\n",
    "    for c in param['c']:\n",
    "        lr = LogisticRegression(C = c, solver = s, class_weight='balanced')\n",
    "        lr.fit(X_train_o, y_train_o)\n",
    "        result = lr.score(tfidf_matrix_test, y_test)\n",
    "        print(\"Solver: \"+str(s)+\", c: \"+str(c)+\", accurancy: \" + str(result))\n",
    "        if result > best_score:\n",
    "            best_score = result\n",
    "            best_solver = s\n",
    "            best_c = c\n",
    "lr =LogisticRegression(C = best_c, solver = best_solver, class_weight='balanced')\n",
    "lr.fit(bow_matrix_train, y_train)\n",
    "print('best param: solver = ' +str(best_solver)+ \", c: \"+str(c)+\" with accuracy:\" + str(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68ddd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "alpha = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100]\n",
    "best_score = 0\n",
    "best_alpha = 0\n",
    "for a in alpha:\n",
    "    \n",
    "    rr = RidgeClassifier(alpha = a, class_weight='balanced')\n",
    "    rr.fit(bow_matrix_train, y_train)\n",
    "    result = rr.score(bow_matrix_test, y_test)\n",
    "    print(\"alpha: \"+str(a)+\", accurancy: \" + str(result))\n",
    "    if result > best_score:\n",
    "        best_score = result\n",
    "        best_alpha = a\n",
    "lr =RidgeClassifier(alpha = best_alpha, class_weight='balanced')\n",
    "lr.fit(bow_matrix_train, y_train)\n",
    "print('best param: alpha = ' +str(best_alpha)+\" with accuracy:\" + str(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68551eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "alpha = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100]\n",
    "best_score = 0\n",
    "best_alpha = 0\n",
    "for a in alpha:\n",
    "    \n",
    "    rr = RidgeClassifier(alpha = a, class_weight='balanced')\n",
    "    rr.fit(tfidf_matrix_train, y_train)\n",
    "    result = rr.score(tfidf_matrix_test, y_test)\n",
    "    print(\"alpha: \"+str(a)+\", accurancy: \" + str(result))\n",
    "    if result > best_score:\n",
    "        best_score = result\n",
    "        best_alpha = a\n",
    "lr =RidgeClassifier(alpha = best_alpha, class_weight='balanced')\n",
    "lr.fit(bow_matrix_train, y_train)\n",
    "print('best param: alpha = ' +str(best_alpha)+\" with accuracy:\" + str(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f483acc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "X_train_o, y_train_o = oversample.fit_resample(bow_matrix_train, y_train)\n",
    "    \n",
    "alpha = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100]\n",
    "best_score = 0\n",
    "best_alpha = 0\n",
    "for a in alpha:\n",
    "    \n",
    "    rr = RidgeClassifier(alpha = a, class_weight='balanced')\n",
    "    rr.fit(X_train_o, y_train_o)\n",
    "    result = rr.score(bow_matrix_test, y_test)\n",
    "    print(\"alpha: \"+str(a)+\", accurancy: \" + str(result))\n",
    "    if result > best_score:\n",
    "        best_score = result\n",
    "        best_alpha = a\n",
    "lr =RidgeClassifier(alpha = best_alpha, class_weight='balanced')\n",
    "lr.fit(bow_matrix_train, y_train)\n",
    "print('best param: alpha = ' +str(best_alpha)+\" with accuracy:\" + str(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df11761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "X_train_o, y_train_o = oversample.fit_resample(tfidf_matrix_train, y_train)\n",
    "    \n",
    "alpha = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100]\n",
    "best_score = 0\n",
    "best_alpha = 0\n",
    "for a in alpha:\n",
    "    \n",
    "    rr = RidgeClassifier(alpha = a, class_weight='balanced')\n",
    "    rr.fit(X_train_o, y_train_o)\n",
    "    result = rr.score(tfidf_matrix_test, y_test)\n",
    "    print(\"alpha: \"+str(a)+\", accurancy: \" + str(result))\n",
    "    if result > best_score:\n",
    "        best_score = result\n",
    "        best_alpha = a\n",
    "lr =RidgeClassifier(alpha = best_alpha, class_weight='balanced')\n",
    "lr.fit(bow_matrix_train, y_train)\n",
    "print('best param: alpha = ' +str(best_alpha)+\" with accuracy:\" + str(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b489a886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbb5136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57de2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_range = np.logspace(-2, 5, 8)\n",
    "gamma_range = np.logspace(-6, 1, 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow_matrix_1, d1['label'], test_size=0.2, random_state=42)\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set.\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "#roc_auc = roc_auc_score(y_test, svm.predict_proba(X_test)[:, 1])\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"f1: {f1}\")\n",
    "#print(f\"roc_auc_score: {roc_auc}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d8bad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow_matrix_2, d2['label'], test_size=0.2, random_state=42)\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set.\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "#roc_auc = roc_auc_score(y_test, svm.predict_proba(X_test)[:, 1])\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"f1: {f1}\")\n",
    "#print(f\"roc_auc_score: {roc_auc}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012e3948",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow_matrix_2, d2['label'], test_size=0.2, random_state=42)\n",
    "svm = SVC(class_weight='balanced')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set.\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "#roc_auc = roc_auc_score(y_test, svm.predict_proba(X_test)[:, 1])\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"f1: {f1}\")\n",
    "#print(f\"roc_auc_score: {roc_auc}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d018351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train_o, y_train_o = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(bow_matrix_2, d2['label'], test_size=0.2, random_state=42)\n",
    "svm = SVC()\n",
    "svm.fit(X_train_o, y_train_o)\n",
    "\n",
    "# Predict on the test set.\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "#roc_auc = roc_auc_score(y_test, svm.predict_proba(X_test)[:, 1])\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"f1: {f1}\")\n",
    "#print(f\"roc_auc_score: {roc_auc}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5398f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train_o, y_train_o = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(bow_matrix_2, d2['label'], test_size=0.2, random_state=42)\n",
    "svm = SVC(class_weight='balanced')\n",
    "svm.fit(X_train_o, y_train_o)\n",
    "\n",
    "# Predict on the test set.\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "#roc_auc = roc_auc_score(y_test, svm.predict_proba(X_test)[:, 1])\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"f1: {f1}\")\n",
    "#print(f\"roc_auc_score: {roc_auc}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daad1a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "evaluate(tfidf_matrix_train, y_train, tfidf_matrix_test, y_test, SVC(class_weight='balanced', probability = True), d1_len, svmsmote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9962ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46d4e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "031b851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_json(path_or_buf=\"./data/test_Set.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0310efe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rainstyle/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "X_train_2_o, y_train_2_o = oversample.fit_resample(tfidf_matrix_train[d1_len:], y_train[d1_len:])\n",
    "X_train_o = sp.sparse.vstack((tfidf_matrix_train[:d1_len], X_train_2_o))\n",
    "y_train_o = np.append(y_train[:d1_len], y_train_2_o)\n",
    "\n",
    "model.fit(X_train_o, y_train_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0effae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vectorizer.transform(test_set['text'].apply(lambda x: \" \".join(map(str, x))))\n",
    "test = tfidf.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1233cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab91da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['class'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d079120a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  class\n",
       "0      0      1\n",
       "1      1      0\n",
       "2      2      1\n",
       "3      3      0\n",
       "4      4      0\n",
       "..   ...    ...\n",
       "995  995      0\n",
       "996  996      1\n",
       "997  997      0\n",
       "998  998      1\n",
       "999  999      1\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[['id', 'class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e23a0253",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = test_set[['id', 'class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8709dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('output.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3419b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
