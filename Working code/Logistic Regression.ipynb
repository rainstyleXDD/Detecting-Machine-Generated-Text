{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "429a1687-9969-4037-961a-14cb09880c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json, csv\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75fcf078-751d-4dcd-b3cd-74a2c8d11ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/agkat/Documents/College/1. SML/A1/domain1_train.json', 'r') as file:\n",
    "   domain1_data = [json.loads(line) for line in file]\n",
    "\n",
    "with open('C:/Users/agkat/Documents/College/1. SML/A1/domain2_train.json', 'r') as file:\n",
    "    domain2_data = [json.loads(line) for line in file]\n",
    "\n",
    "# Combine the data from both domains\n",
    "combined_data = domain1_data + domain2_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3bd249f9-065d-47e1-9f4b-3796b44a4f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1075\n"
     ]
    }
   ],
   "source": [
    "print(max([len(x['text']) for x in combined_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9632659a-e073-4403-a893-66a6234548dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the combined data into training and validation sets\n",
    "train_data, val_data = train_test_split(combined_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Separate the text and labels from the training set\n",
    "train_texts = [instance['text'] for instance in train_data]\n",
    "train_labels = [instance['label'] for instance in train_data]\n",
    "\n",
    "\n",
    "# Separate the text and labels from the validation set\n",
    "val_texts = [instance['text'] for instance in val_data]\n",
    "val_labels = [instance['label'] for instance in val_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e84804c-cdfc-4958-99bb-ddcb3508079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_texts = pad_sequences(val_texts, padding='post', value=-1, maxlen=1075)\n",
    "train_texts = pad_sequences(train_texts, padding='post', value=-1, maxlen=1075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "610e0a43-ca1a-4836-8e1b-e0ce2915d627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 11, 182, 158, ...,   0,   0,   0])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.array(x) for x in train_texts][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2650d822-89b8-47d5-ad85-5a129727676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of lists into a numpy array\n",
    "X = np.array([np.array(lst) for lst in train_texts])\n",
    "X = np.add(X, 1)\n",
    "\n",
    "# Create the target vector\n",
    "y = np.array(train_labels)\n",
    "\n",
    "# Convert the validation sets as well:\n",
    "X_val = np.array([np.array(lst) for lst in val_texts])\n",
    "X_val = np.add(X_val, 1)\n",
    "\n",
    "# Create the target vector\n",
    "y = np.array(train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a55a1bb-9160-425a-a6b0-f4776bd242db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 12, 183, 159, ...,   0,   0,   0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029c1d5c-c3e1-4435-93e0-2b151a6c4819",
   "metadata": {},
   "source": [
    "# Log regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3889a9b4-b288-46c0-9238-7f4a4f632845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agkat\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(penalty=None)\n",
    "clf.fit(X, y)\n",
    "w_sklearn = np.r_[clf.intercept_, clf.coef_.squeeze()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1ec00ef-9cf0-4b62-a0c4-c3fc8af1c253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.703343023255814"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "accuracy_score(val_labels, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8bd5e62-02d3-4aca-93eb-65e531a30b97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create an instance of the MultinomialNB classifier\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "# Fit the classifier on the training data\n",
    "classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76f1bfce-fa77-407f-a47b-097381e46544",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6168604651162791"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the labels for the validation set\n",
    "y_pred = classifier.predict(X_val)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(val_labels, y_pred)\n",
    "\n",
    "accuracy\n",
    "# with padded 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "560e3591-5406-4aca-9cc6-dc2442770769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6168604651162791"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the labels for the validation set\n",
    "y_pred = classifier.predict(X_val)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(val_labels, y_pred)\n",
    "\n",
    "accuracy\n",
    "# with padded 0s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28cbdd6-0ebb-4ece-a578-c8dde438b020",
   "metadata": {},
   "source": [
    "# Importing the test set and running the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9eb2917c-071f-43ba-be7a-9e72ab24c760",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/agkat/Documents/College/1. SML/A1/test_set.json', 'r') as file:\n",
    "   test_data = [json.loads(line) for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1528c161-5c73-4232-8255-c899ea169440",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'text': [59,\n",
       "  2,\n",
       "  3434,\n",
       "  1013,\n",
       "  823,\n",
       "  2,\n",
       "  887,\n",
       "  6,\n",
       "  2375,\n",
       "  0,\n",
       "  34,\n",
       "  43,\n",
       "  584,\n",
       "  18,\n",
       "  0,\n",
       "  0,\n",
       "  6,\n",
       "  686,\n",
       "  1,\n",
       "  56,\n",
       "  43,\n",
       "  2881,\n",
       "  1107,\n",
       "  0,\n",
       "  287,\n",
       "  1495,\n",
       "  9,\n",
       "  2,\n",
       "  1013,\n",
       "  71,\n",
       "  447,\n",
       "  2,\n",
       "  3519,\n",
       "  0,\n",
       "  118,\n",
       "  13,\n",
       "  10,\n",
       "  532,\n",
       "  81,\n",
       "  1,\n",
       "  13,\n",
       "  8,\n",
       "  15,\n",
       "  329,\n",
       "  10,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  4083,\n",
       "  1372,\n",
       "  2938,\n",
       "  3,\n",
       "  7,\n",
       "  13,\n",
       "  41,\n",
       "  0,\n",
       "  120,\n",
       "  156,\n",
       "  4752,\n",
       "  1013,\n",
       "  1,\n",
       "  30,\n",
       "  4083,\n",
       "  11,\n",
       "  269,\n",
       "  661,\n",
       "  114,\n",
       "  4,\n",
       "  2,\n",
       "  3217,\n",
       "  6,\n",
       "  713,\n",
       "  1,\n",
       "  944,\n",
       "  57,\n",
       "  4,\n",
       "  0,\n",
       "  551,\n",
       "  1,\n",
       "  39,\n",
       "  329,\n",
       "  17,\n",
       "  0,\n",
       "  1565,\n",
       "  0,\n",
       "  1,\n",
       "  11,\n",
       "  240,\n",
       "  5,\n",
       "  802,\n",
       "  6,\n",
       "  2,\n",
       "  0,\n",
       "  1683,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  7,\n",
       "  6,\n",
       "  2,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  3,\n",
       "  74,\n",
       "  0,\n",
       "  422,\n",
       "  22,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  11,\n",
       "  10,\n",
       "  186,\n",
       "  497,\n",
       "  842,\n",
       "  3490,\n",
       "  144,\n",
       "  33,\n",
       "  2,\n",
       "  0,\n",
       "  6,\n",
       "  451,\n",
       "  3,\n",
       "  202,\n",
       "  73,\n",
       "  11,\n",
       "  55,\n",
       "  774,\n",
       "  608,\n",
       "  1,\n",
       "  11,\n",
       "  32,\n",
       "  1122,\n",
       "  22,\n",
       "  2,\n",
       "  4083,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  2671,\n",
       "  4744,\n",
       "  136,\n",
       "  120,\n",
       "  1013,\n",
       "  3,\n",
       "  270,\n",
       "  4,\n",
       "  945,\n",
       "  157,\n",
       "  2620,\n",
       "  1,\n",
       "  59,\n",
       "  2,\n",
       "  0,\n",
       "  3782,\n",
       "  2671,\n",
       "  0,\n",
       "  0,\n",
       "  7,\n",
       "  821,\n",
       "  81,\n",
       "  415,\n",
       "  1226,\n",
       "  1381,\n",
       "  7,\n",
       "  2,\n",
       "  688,\n",
       "  1043,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  681,\n",
       "  6,\n",
       "  0,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  574,\n",
       "  6,\n",
       "  3537,\n",
       "  1134,\n",
       "  157,\n",
       "  7,\n",
       "  89,\n",
       "  0,\n",
       "  2155,\n",
       "  4,\n",
       "  661,\n",
       "  30,\n",
       "  0,\n",
       "  4,\n",
       "  2,\n",
       "  2381,\n",
       "  1]}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "81a19823-aa64-4cc9-add1-9c7d9b762d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the text and labels from the training set\n",
    "test_text = [instance['text'] for instance in test_data]\n",
    "test_text = pad_sequences(test_text, padding='post', value=0, maxlen=1075)\n",
    "X_test = np.array([np.array(lst) for lst in train_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "adf8f818-4514-477f-b720-7a718da47904",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3ae36e18-f96c-4831-82d3-da4e754fc3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = csv.writer(open('C:/Users/agkat/Documents/College/1. SML/A1/test_result.csv', 'w'))\n",
    "response.writerow(('id', 'class'))\n",
    "for p in range(len(prediction)):\n",
    "    # print(p, prediction[p])\n",
    "    response.writerow((p, prediction[p]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
